{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b92fc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a5a6f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Path to your JSON file\n",
    "file_path = \"Datasets/file_analysis_2/fa2.json\"\n",
    "\n",
    "# Load the JSON content\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract parts from the JSON\n",
    "scenario = data[\"scenario\"]\n",
    "tools = data[\"tools\"]\n",
    "questions = data[\"questions\"]\n",
    "file=data[\"files\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff39820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExecuteCmd(command_str) -> str:\n",
    "    \"\"\"Execute a shell command and save its output to a file.\n",
    "\n",
    "    Args:\n",
    "        command_str: The shell command to execute as a string.\n",
    "\n",
    "    Returns:\n",
    "        A message indicating that the output was saved in a file.\n",
    "    \"\"\"\n",
    "    output_file = 'output_cmd/output.txt'\n",
    "    with open(output_file, 'w') as f:\n",
    "        subprocess.run(\n",
    "            command_str,\n",
    "            shell=True,\n",
    "            stderr=f,\n",
    "            stdout=f,\n",
    "            text=True,\n",
    "            executable='/bin/bash'\n",
    "        )\n",
    "    return f\"Output saved in a file\"\n",
    "\n",
    "\n",
    "# Tool 1: get the next question from a list\n",
    "def next_question() -> str:\n",
    "    \"\"\"This tool reads and returns the next question and can be used to get the first question.\"\"\"\n",
    "    global i, questions\n",
    "    i += 1\n",
    "    return questions[i-1]\n",
    "\n",
    "# Tool 2: read the command output file\n",
    "def read_output() -> str:\n",
    "    \"\"\"This tool reads the file where command outputs are stored and returns its content(may be truncated if output is very long).\"\"\"\n",
    "    output_file = 'output_cmd/output.txt'\n",
    "    with open(output_file, 'r') as f:\n",
    "        output = f.read()\n",
    "    if len(output) > 500:\n",
    "        output = output[:500] + \"\\n...[truncated]...\"\n",
    "    return output.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These function declarations are passed to the llm, then the llm decides which tool to call\n",
    "ExecuteCmd_dec = {\n",
    "    \"name\": \"ExecuteCmd\",\n",
    "    \"description\": \"Execute a shell command and save its output to a file.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"command_str\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The shell command to execute.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"command_str\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "next_question_dec = {\n",
    "    \"name\": \"next_question\",\n",
    "    \"description\": \"Reads and returns the next question and can be used to get the first question.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {},  # no parameters required\n",
    "        \"required\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "read_output_dec = {\n",
    "    \"name\": \"read_output\",\n",
    "    \"description\": \"Reads the file where command outputs are stored and returns its content. Output may be truncated if very long.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {},  # no parameters required\n",
    "        \"required\": []\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487d5b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" You run in a loop of Thought, Action, Observation.\n",
    "At the end of the loop you output an Answer.\n",
    "Use Thought to describe your thoughts about the task you have been given.\n",
    "Use Action to run one of the tools available to you using Function Calling.\n",
    "Observation will be the result of running those actions.\n",
    "Provide thought after each prompt in this format: Thought: <Your reasoning and thinking>\n",
    "\n",
    "The most important rule STRICTLY follow:\n",
    "- Use function calling only if you have output a Thought in the previous request\n",
    "- Thought and Function calling should be in different interactions  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e73db851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are tasked with solving a cybersecurity investigation challenge composed of multiple sequential questions. Use only Ubuntu terminal commands to analyze the provided file and answer each question in order.\n",
      "\n",
      "Scenario:\n",
      "A suspicious Pwershell script in a .txt file was found on one of our endpoints, can you work out what it does?\n",
      "\n",
      "Available Command-line tools you can use:\n",
      "grep, awk, sed, sha256sum, base64, cut, sort, wc, head, tail, find, strings, file, stat\n",
      "\n",
      "Target File:\n",
      "Datasets/file_analysis_2/HDWallpaperEngine.txt \n",
      "\n",
      "1. When user says: \"Take the next question and solve it by providing a linux command\"\n",
      "   - THOUGHT: Analyze the provided question. Explain your planned approach.\n",
      "   - ACTION: Use next_question() to retrieve the question\n",
      "\n",
      "2. After receiving question via Observation:\n",
      "   - THOUGHT: Design a command to answer the question\n",
      "   - ACTION: ExecuteCmd(command_str='...')\n",
      "\n",
      "3. When user says: \"Analyze the previous command's output and generate a new command or return the final answer\"\n",
      "   - THOUGHT: Evaluate the output. Determine if answer is present or if further analysis is needed\n",
      "   - ACTION: EITHER use read_output() OR provide Answer: \n",
      "\n",
      "4. After reading output via Observation:\n",
      "   - THOUGHT: Verify if output contains the answer\n",
      "   - ACTION: EITHER ExecuteCmd() for refinement OR Answer: \n",
      "\n",
      "RULES (MUST OBEY):\n",
      "1. ALWAYS output Thought before Action in separate interactions\n",
      "2. NEVER combine Thought and Action in same response\n",
      "3. For multi-step analysis: chain commands using pipes (|)\n",
      "4. When answer is found: Output immediately in \"Answer: \" format\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example session:\n",
      "\n",
      "Task by the user: Take the next question and solve it by providing a linux command\n",
      "\n",
      "Thought: I need to retrieve the question\n",
      "Action: next question retrival\n",
      "\n",
      "You will be called again with this:\n",
      "\n",
      "Observation: the next question\n",
      "\n",
      "Thought: I need to generate a command to solve the question \n",
      "Action: Execute command\n",
      "\n",
      "You will be called again with this:\n",
      "\n",
      "Task by the user: Analyze the previous command's output and generate a new command or return the final answer\n",
      "\n",
      "Thought: i need to see the output of the command\n",
      "Action: read the output\n",
      "\n",
      "You will be called again with this:\n",
      "\n",
      "Observation: the output of the command\n",
      "\n",
      "Thought: I need to check if the answer is in the output, if not i will give another command \n",
      "Action: Execute command\n",
      "OR\n",
      "Answer: answer to the question\n",
      "\n",
      "You will be called again with this:\n",
      "Task by the user: Take the next question and solve it by providing a linux command\n"
     ]
    }
   ],
   "source": [
    "prompt= f\"\"\"\n",
    "You are tasked with solving a cybersecurity investigation challenge composed of multiple sequential questions. Use only Ubuntu terminal commands to analyze the provided file and answer each question in order.\n",
    "\n",
    "Scenario:\n",
    "{scenario}\n",
    "\n",
    "Available Command-line tools you can use:\n",
    "{', '.join(tools)}\n",
    "\n",
    "Target File:\n",
    "{', '.join(file)} \n",
    "\n",
    "1. When user says: \"Take the next question and solve it by providing a linux command\"\n",
    "   - THOUGHT: Analyze the provided question. Explain your planned approach.\n",
    "   - ACTION: Use next_question() to retrieve the question\n",
    "\n",
    "2. After receiving question via Observation:\n",
    "   - THOUGHT: Design a command to answer the question\n",
    "   - ACTION: ExecuteCmd(command_str='...')\n",
    "\n",
    "3. When user says: \"Analyze the previous command's output and generate a new command or return the final answer\"\n",
    "   - THOUGHT: Evaluate the output. Determine if answer is present or if further analysis is needed\n",
    "   - ACTION: EITHER use read_output() OR provide Answer: \n",
    "\n",
    "4. After reading output via Observation:\n",
    "   - THOUGHT: Verify if output contains the answer\n",
    "   - ACTION: EITHER ExecuteCmd() for refinement OR Answer: \n",
    "\n",
    "RULES (MUST OBEY):\n",
    "1. ALWAYS output Thought before Action in separate interactions\n",
    "2. NEVER combine Thought and Action in same response\n",
    "3. For multi-step analysis: chain commands using pipes (|)\n",
    "4. When answer is found: Output immediately in \"Answer: \" format\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Example session:\n",
    "\n",
    "Task by the user: Take the next question and solve it by providing a linux command\n",
    "\n",
    "Thought: I need to retrieve the question\n",
    "Action: next question retrival\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: the next question\n",
    "\n",
    "Thought: I need to generate a command to solve the question \n",
    "Action: Execute command\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Task by the user: Analyze the previous command's output and generate a new command or return the final answer\n",
    "\n",
    "Thought: i need to see the output of the command\n",
    "Action: read the output\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: the output of the command\n",
    "\n",
    "Thought: I need to check if the answer is in the output, if not i will give another command \n",
    "Action: Execute command\n",
    "OR\n",
    "Answer: answer to the question\n",
    "\n",
    "You will be called again with this:\n",
    "Task by the user: Take the next question and solve it by providing a linux command \"\"\".strip()\n",
    "print (prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d614be9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: next_question()\n",
      "Observation: What is the SHA256 hash value for the PowerShell script file?\n",
      "Action: ExecuteCmd(command_str='sha256sum Datasets/file_analysis_2/HDWallpaperEngine.txt')\n",
      "Observation: Output saved in a file\n",
      "Action: read_output()\n",
      "Observation: e0b7a2ad2320ac32c262aeb6fe2c6c0d75449c6e34d0d18a531157c827b9754e  Datasets/file_analysis_2/HDWallpaperEngine.txt\n",
      "Answer: e0b7a2ad2320ac32c262aeb6fe2c6c0d75449c6e34d0d18a531157c827b9754e\n",
      "Action: next_question()\n",
      "Observation: What email address is used to send and receive emails? (Format: Mailbox@domain.tld)\n",
      "Action: ExecuteCmd(command_str=\"grep -oE '\\\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Z|a-z]{2,}\\\\b' Datasets/file_analysis_2/HDWallpaperEngine.txt\")\n",
      "Observation: Output saved in a file\n",
      "Action: read_output()\n",
      "Observation: chaudhariparth454@gmail.com\n",
      "chaudhariparth454@gmail.com\n",
      "Answer: chaudhariparth454@gmail.com\n",
      "Action: next_question()\n",
      "Observation: What is the password for this email account?\n",
      "Action: ExecuteCmd(command_str=\"grep -iE 'password|pass|pwd|chaudhariparth454@gmail.com' Datasets/file_analysis_2/HDWallpaperEngine.txt\")\n",
      "Observation: Output saved in a file\n",
      "Action: read_output()\n",
      "Observation: $From = \"chaudhariparth454@gmail.com\"\n",
      "$Pass = \"yjghfdafsd5464562!\"\n",
      "$To = \"chaudhariparth454@gmail.com\"\n",
      "$credentials = new-object Management.Automation.PSCredential $From, ($Pass | ConvertTo-SecureString -AsPlainText -Force)\n",
      "  $API = Add-Type -MemberDefinition $signatures -Name 'Win32' -Namespace API -PassThru\n",
      "Answer: yjghfdafsd5464562!\n",
      "Action: next_question()\n",
      "Observation: What port is used for SMTP? (Format: Port Number)\n",
      "Action: ExecuteCmd(command_str=\"grep -oE '([0-9]{2,5})' Datasets/file_analysis_2/HDWallpaperEngine.txt | sort -u\")\n",
      "Observation: Output saved in a file\n",
      "Action: read_output()\n",
      "Observation: 254\n",
      "256\n",
      "32\n",
      "32767\n",
      "40\n",
      "454\n",
      "54645\n",
      "587\n",
      "62\n",
      "Answer: 587\n",
      "Action: next_question()\n",
      "Observation: What DLL is imported to help record keystrokes? (Format: filename.extension)\n",
      "Action: ExecuteCmd(command_str=\"grep -iE 'dll|hook|SetWindowsHookEx' Datasets/file_analysis_2/HDWallpaperEngine.txt\")\n",
      "Observation: Output saved in a file\n",
      "Action: read_output()\n",
      "Observation: [DllImport(\"user32.dll\", CharSet=CharSet.Auto, ExactSpelling=true)] \n",
      "[DllImport(\"user32.dll\", CharSet=CharSet.Auto)]\n",
      "[DllImport(\"user32.dll\", CharSet=CharSet.Auto)]\n",
      "[DllImport(\"user32.dll\", CharSet=CharSet.Auto)]\n",
      "Answer: user32.dll\n",
      "Action: next_question()\n",
      "Observation: What directory is the generated txt file put in? (Format: directory name)\n",
      "Action: ExecuteCmd(command_str=\"grep -iE '\\\\.txt|\\\\$env:temp' Datasets/file_analysis_2/HDWallpaperEngine.txt\")\n",
      "Observation: Output saved in a file\n"
     ]
    }
   ],
   "source": [
    "#create a chat session\n",
    "chat = client.chats.create(\n",
    "            #history=[],\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            config=types.GenerateContentConfig(\n",
    "                    # here are the external functions' declarations that the LLM will call to solve the problem\n",
    "                    tools=[types.Tool(function_declarations=[ExecuteCmd_dec,next_question_dec,read_output_dec])], \n",
    "                    system_instruction=prompt #system prompt\n",
    "                    \n",
    "                ))\n",
    "i=0\n",
    "answer_list=[\"answer not found\"]*len(questions)\n",
    "\n",
    "while i<len(questions):\n",
    "        \n",
    "        # we limit the yser to enter \"1\", \"2\" or \"3\" to choose what to tell the model\n",
    "        user_input = int(input(\"Enter 1 to solve the next question or 2 to further analyse the question: \"))\n",
    "        if user_input == 1:\n",
    "            query = \"Take the next question and solve it by providing a linux command always generate thought before calling\"\n",
    "            \n",
    "        elif user_input == 2:\n",
    "            query = \"Analyze the previous command's output and generate a new command or return the final answer\"\n",
    "\n",
    "        elif user_input ==3:break    \n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 1 or 2.\")\n",
    "\n",
    "        #loop \n",
    "        j=0 \n",
    "        MaxAttempts=4\n",
    "        next_input=query\n",
    "        responselist=[]\n",
    "        while j<MaxAttempts:\n",
    "            j+=1\n",
    "            #this is the request that triggers gemini\n",
    "            response= chat.send_message(next_input)\n",
    "            parts=response.candidates[0].content.parts[0]\n",
    "            # Check for a function call\n",
    "            if parts.function_call:\n",
    "                responselist.append(response.candidates)\n",
    "                tool_call = parts.function_call\n",
    "                args_str = \", \".join(f\"{k}={repr(v)}\" for k, v in tool_call.args.items())\n",
    "                print(f\"Action: {tool_call.name}({args_str})\")\n",
    "\n",
    "                if tool_call.name == \"ExecuteCmd\":\n",
    "                    result = ExecuteCmd(**tool_call.args)#there is break here\n",
    "                    print(f\"Observation: {result}\")\n",
    "                    break\n",
    "                elif tool_call.name== \"next_question\":\n",
    "                    result = next_question()\n",
    "                else: result= read_output()\n",
    "\n",
    "                next_input=f\"Observation: {result}\"\n",
    "                print(next_input)\n",
    "                \n",
    "            else:\n",
    "\n",
    "                print(parts.text)                \n",
    "                match = re.search(r\"(?i)answer\\s*:\\s*(.*)\", parts.text)\n",
    "                if match:\n",
    "                    answer_list[i-1]=match.group(1).strip()  # Extract text after 'Answer:'\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ac12947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e0b7a2ad2320ac32c262aeb6fe2c6c0d75449c6e34d0d18a531157c827b9754e', 'chaudhariparth454@gmail.com', 'yjghfdafsd5464562!', '587', 'user32.dll', 'answer not found']\n"
     ]
    }
   ],
   "source": [
    "print(answer_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
